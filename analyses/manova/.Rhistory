# pki <- read.csv("D:/Dropbox/FourchesLab/3I60/pkis.csv")
pki <- read.csv("C:/Users/jrash/ubuntu_share/Google Drive/FourchesLab/3I60/pkis.csv")
pki$row.ID = as.character(pki$row.ID)
pki[,1] = sub("CSAR_erk2","CSAR", pki[,1])
pki[,1] = sub("erk2","Model", pki[,1])
pki <- pki[pki$row.ID %in% intersect(pki$row.ID, d$row.ID),]
d_pki = merge(pki, d, by.x= "row.ID", by.y= "row.ID")
head(d_pki[1:6])
rownames(d_pki) = d_pki[,1]
d_pki = d_pki[,-1]
activity <- cut(d_pki$pki, c(9,7.5,4),
labels = rev(c("active", "inactive")))
d_pki$pki = NULL
dim(d_pki)
lmfit = lm(d_pki[,5]~activity)
summary(aov(lmfit))
varNum = dim(d_pki)[2]
pkimodels <- vector("list", (varNum))
pkimodelspvals <- vector("list", (varNum))
pkimodelseffect <- vector("list", (varNum))
vars = colnames(d_pki)[1:(varNum)]
head(d_pki[1:6])
i=10
for (i in 1:(varNum)){
if(grepl("Bit", colnames(d_pki)[i])){
#check that it is alright to combine p-values for logistic regression and ANOVA
lmfit <- glm(d_pki[,i]~activity, family = "binomial")
}else{
lmfit <- lm(d_pki[,i]~activity)
}
pkimodels[[i]] <- lmfit
#pvalue for regressing each variable in df on AC50
pkimodelspvals[[i]] <- summary(aov(lmfit))[[1]][1,5]
datFile_norm =  scale(d_pki)
pkimodelseffect[[i]] <- mean(datFile_norm[activity == "active",i]) - mean(datFile_norm[activity == "inactive",i])
}
pki_effect = unlist(pkimodelseffect)
plot(pki_effect)
CohenD <- pki_effect
#bonferroni correction p-value
.05/varNum
pki_ps = unlist(pkimodelspvals)
pki_ps <- p.adjust(pki_ps, method = "BH")
pki_res = data.frame(des_set = c(rep("MACCS", 97), rep("2D", 65),rep("3D", 20), rep("MD", 44)), variables = vars, pvalues = pki_ps, CohenD = CohenD)
sig_pki = cbind(as.character(pki_res$des_set[pki_ps<=0.05]),vars[pki_ps<0.05],pki_ps[pki_ps<0.05],CohenD[pki_ps<0.05])
#sig descriptors
table(pki_res[pki_ps<=0.05,]$des_set)
pki_res[order(pki_res$pvalues,decreasing = F),]
sig_pki = as.data.frame(sig_pki)
sig_pki[,3] <-  as.numeric(as.character(sig_pki[,3]))
sig_pki[,4] <-  as.numeric(as.character(sig_pki[,4]))
colnames(sig_pki) <- c("Descriptor Set", "Variable", "P-Value", "Cohen's D")
sig_pki = sig_pki[order(sig_pki[,"P-Value"],decreasing = F),]
sig_pki_c <- sig_pki
sig_pki_c$Variable <- sub("\\.x", ".mean", sig_pki_c$Variable)
sig_pki_c$Variable <- sub("\\.y", ".sd", sig_pki_c$Variable)
x_tab = xtable(sig_pki_c)
digits(x_tab) <- c(0,0,0,-2,2)
print(x_tab, include.rownames = FALSE)
tmp <- matrix(rnorm(9), 3, 3)
xtmp <- xtable(tmp)
digits(xtmp) <- c(0,0,3,4)
print(xtmp, include.rownames = FALSE) # row names
sig_pki_c$Variable <- sub("\\.mean", "", sig_pki_c$Variable)
sig_pki_c$Variable <- sub("\\.sd", "", sig_pki_c$Variable)
sig_pki_c
three_filter <- sig_pki_c$Variable[sig_pki_c$`Descriptor Set`=="3D"]
MD_filter <- sig_pki_c$Variable[sig_pki_c$`Descriptor Set`=="MD"]
sum(!(MD_filter %in% three_filter))
MD_filter[!(MD_filter %in% three_filter)]
list.of.packages <- c("qqman","xtable","caret","randomForest","cluster","psych","fpc",
"mclust","fastcluster","ggbiplot","boot","bootstrap","vegan","caret")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only = TRUE)
library(gplots)
library(RColorBrewer)
rm(list=ls())
# setwd("D:/Dropbox/FourchesLab/3I60/docking_results/docking_results8-14/highVarDescriptors")
setwd("C:/Users/jrash/ubuntu_share/Google Drive/FourchesLab/3I60/docking_results/docking_results8-14/highVarDescriptors/")
# PCA
fing <- read.csv("procDesFingMACCS_all.csv", row.names = 1)
fing <- fing[-findCorrelation(cor(fing), cutoff = .9)]
twoD <- read.csv("procDes2D_all.csv", row.names = 1)
twoD <- twoD[-findCorrelation(cor(twoD), cutoff = .9)]
threeD <- read.csv("procDes3D_all.csv", row.names = 1)
threeD <- threeD[-findCorrelation(cor(threeD), cutoff = .9)]
fourD <- read.csv("procDes4D_all.csv", row.names = 1)
fourD <- fourD[-findCorrelation(cor(fourD), cutoff = .9)]
dim(fing)
dim(twoD)
dim(threeD)
dim(fourD)
all <- cbind(fing,twoD,threeD, fourD)
findCorrelation(cor(all), verbose=T)
# cor.plot(cbind(threeD[,20:30],fourD[,c(20:30, 75:85)]))
# max(cor(fourD[, c("Atomic.Masses.Weta3.y", "Atomic.Masses.Weta3.x")], fourD[,-c(29, 80)]))
d <- all
# d <- all[-c(126,150,197)]
d$row.ID <- rownames(d)
# pki <- read.csv("D:/Dropbox/FourchesLab/3I60/pkis.csv")
pki <- read.csv("C:/Users/jrash/ubuntu_share/Google Drive/FourchesLab/3I60/pkis.csv")
pki$row.ID = as.character(pki$row.ID)
pki[,1] = sub("CSAR_erk2","CSAR", pki[,1])
pki[,1] = sub("erk2","Model", pki[,1])
pki <- pki[pki$row.ID %in% intersect(pki$row.ID, d$row.ID),]
d_pki = merge(pki, d, by.x= "row.ID", by.y= "row.ID")
head(d_pki[1:6])
rownames(d_pki) = d_pki[,1]
d_pki = d_pki[,-1]
activity <- cut(d_pki$pki, c(9,7.5,4),
labels = rev(c("active", "inactive")))
d_pki$pki = NULL
dim(d_pki)
lmfit = lm(d_pki[,5]~activity)
summary(aov(lmfit))
varNum = dim(d_pki)[2]
pkimodels <- vector("list", (varNum))
pkimodelspvals <- vector("list", (varNum))
pkimodelseffect <- vector("list", (varNum))
vars = colnames(d_pki)[1:(varNum)]
head(d_pki[1:6])
i=10
for (i in 1:(varNum)){
if(grepl("Bit", colnames(d_pki)[i])){
#check that it is alright to combine p-values for logistic regression and ANOVA
lmfit <- glm(d_pki[,i]~activity, family = "binomial")
}else{
lmfit <- lm(d_pki[,i]~activity)
}
pkimodels[[i]] <- lmfit
#pvalue for regressing each variable in df on AC50
pkimodelspvals[[i]] <- summary(aov(lmfit))[[1]][1,5]
datFile_norm =  scale(d_pki)
pkimodelseffect[[i]] <- mean(datFile_norm[activity == "active",i]) - mean(datFile_norm[activity == "inactive",i])
}
pki_effect = unlist(pkimodelseffect)
plot(pki_effect)
CohenD <- pki_effect
#bonferroni correction p-value
.05/varNum
pki_ps = unlist(pkimodelspvals)
pki_ps <- p.adjust(pki_ps, method = "BH")
pki_res = data.frame(des_set = c(rep("MACCS", 97), rep("2D", 65),rep("3D", 20), rep("MD", 44)), variables = vars, pvalues = pki_ps, CohenD = CohenD)
sig_pki = cbind(as.character(pki_res$des_set[pki_ps<=0.05]),vars[pki_ps<0.05],pki_ps[pki_ps<0.05],CohenD[pki_ps<0.05])
#sig descriptors
table(pki_res[pki_ps<=0.05,]$des_set)
pki_res[order(pki_res$pvalues,decreasing = F),]
sig_pki = as.data.frame(sig_pki)
sig_pki[,3] <-  as.numeric(as.character(sig_pki[,3]))
sig_pki[,4] <-  as.numeric(as.character(sig_pki[,4]))
colnames(sig_pki) <- c("Descriptor Set", "Variable", "P-Value", "Cohen's D")
sig_pki = sig_pki[order(sig_pki[,"P-Value"],decreasing = F),]
sig_pki_c <- sig_pki
sig_pki_c$Variable <- sub("\\.x", ".mean", sig_pki_c$Variable)
sig_pki_c$Variable <- sub("\\.y", ".sd", sig_pki_c$Variable)
x_tab = xtable(sig_pki_c)
digits(x_tab) <- c(0,0,0,-2,2)
print(x_tab, include.rownames = FALSE)
tmp <- matrix(rnorm(9), 3, 3)
xtmp <- xtable(tmp)
digits(xtmp) <- c(0,0,3,4)
print(xtmp, include.rownames = FALSE) # row names
sig_pki_c$Variable <- sub("\\.mean", "", sig_pki_c$Variable)
sig_pki_c$Variable <- sub("\\.sd", "", sig_pki_c$Variable)
sig_pki_c
three_filter <- sig_pki_c$Variable[sig_pki_c$`Descriptor Set`=="3D"]
MD_filter <- sig_pki_c$Variable[sig_pki_c$`Descriptor Set`=="MD"]
sum(!(MD_filter %in% three_filter))
MD_filter[!(MD_filter %in% three_filter)]
## Load example dataset
data(tli)
## Demonstrate data.frame
tli.table <- xtable(tli[1:20, ])
print(tli.table)
print(tli.table, type = "html")
xtable(mtcars)
xtable(mtcars, auto = TRUE)
print(x_tab, include.rownames = FALSE)
head(sig_pki_c)
write.csv(sig_pki_c, file = "significant_descriptors.csv")
?prettyNum
xtab
x_tab = xtable(sig_pki_c)
digits(x_tab) <- c(0,0,0,-2,2)
print(x_tab, include.rownames = FALSE)
?xtable
as.data.frame(xtable)
as.matrix(xtable)
data.frame(xtable)
?signif
signif(sig_pki_c)
signif(sig_pki_c$`P-Value`)
signif(sig_pki_c$`P-Value`, digits = 3)
signif(sig_pki_c$`Cohen's D` , digits = 3)
sig_pki_c$`Cohen's D` <- signif(sig_pki_c$`Cohen's D` , digits = 2)
sig_pki_c$`Cohen's D`
write.csv(sig_pki_c, file = "significant_descriptors.csv")
write.csv(sig_pki_c, file = "significant_descriptors.csv")
sig_pki_c$`P-Value` <- signif(sig_pki_c$`P-Value`, digits = 3)
sig_pki_c$`Cohen's D` <- signif(sig_pki_c$`Cohen's D` , digits = 2)
head(sig_pki_c)
sig_pki_c <- sig_pki
sig_pki_c$Variable <- sub("\\.x", ".mean", sig_pki_c$Variable)
sig_pki_c$Variable <- sub("\\.y", ".sd", sig_pki_c$Variable)
x_tab = xtable(sig_pki_c)
digits(x_tab) <- c(0,0,0,-2,2)
print(x_tab, include.rownames = FALSE)
head(sig_pki_c)
sig_pki_c$`P-Value` <- signif(sig_pki_c$`P-Value`, digits = 3)
sig_pki_c$`Cohen's D` <- signif(sig_pki_c$`Cohen's D` , digits = 3)
head(sig_pki_c)
write.csv(sig_pki_c, file = "significant_descriptors.csv")
?signif
sapply(signif(sig_pki_c$`P-Value`,3), sprintf, fmt="%#.3g")
sig_pki_c$`P-Value` <- sapply(signif(sig_pki_c$`P-Value`,3), sprintf, fmt="%#.3g")
sig_pki_c$`Cohen's D` <- sapply(signif(sig_pki_c$`Cohen's D`,3), sprintf, fmt="%#.3g")
head(sig_pki_c)
write.csv(sig_pki_c, file = "significant_descriptors.csv")
head(sig_pki_c)
head(as.character(sig_pki_c))
write.csv(sig_pki_c, file = "significant_descriptors.csv")
type(sig_pki_c$`Cohen's D`)
class(sig_pki_c$`Cohen's D`)
write.csv(sig_pki_c, file = "significant_descriptors.csv")
sig_pki_c$`P-Value` <- sapply(signif(sig_pki_c$`P-Value`,2), sprintf, fmt="%#.3g")
sig_pki_c$`Cohen's D` <- sapply(signif(sig_pki_c$`Cohen's D`,2), sprintf, fmt="%#.3g")
sig_pki_c$`P-Value` <- signif(sig_pki_c$`P-Value`, digits = 2)
sig_pki_c <- sig_pki
sig_pki_c$Variable <- sub("\\.x", ".mean", sig_pki_c$Variable)
sig_pki_c$Variable <- sub("\\.y", ".sd", sig_pki_c$Variable)
x_tab = xtable(sig_pki_c)
digits(x_tab) <- c(0,0,0,-2,2)
print(x_tab, include.rownames = FALSE)
head(sig_pki_c)
sig_pki_c$`P-Value` <- signif(sig_pki_c$`P-Value`, digits = 2)
sig_pki_c$`Cohen's D` <- signif(sig_pki_c$`Cohen's D`, digits = 2)
head(as.character(sig_pki_c))
write.csv(sig_pki_c, file = "significant_descriptors.csv")
list.of.packages <- c("compare","reshape","psych")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only = TRUE)
rm(list=ls()) #################################
setwd("C:/Users/vestige/Google Drive/AlisonConsult/clinvitro/manova/")
processed.dir <- 'C:/Users/Vestige/Google Drive/AlisonConsult/clinvitro/processed/clinical/'
## With_genos.tsv
d <- read.table(file = paste(processed.dir,'With_genos.tsv',sep=''),sep='\t',header=TRUE,stringsAsFactors=FALSE,comment.char = "$")
## Remove unnecessary cols
d <- d[,-c(1,3,5,17,18)]
d <- d[,-c(3:13)]
cols <- colnames(d)
colnames(d) <- c('ID','Race',
#"CYP1B1.3","X2B6.6.516","X2B6.6.785","X2C8.3.139","X2C8.3.399","X3A4.1B","X3A5.3C","ABCB1.3435","ABCB1.2677","ABCB1.1236","GSTA1.B",
'Age',
'Menopause',
'Smoke',
'Grade',
'ER',
'ERorPR',
'HER2',
'IHC',
'Regimen',
'Adjuvant',
'NumCycles',
'StartDate',
'EndDate',
'Toxtype',
'ToxGrade',
'ToxCall',
'Neutropenia',
'Myalgia',
'Neuropathy',
'DoseInterval',
'TotalWeeks',
'FollowupStatus',
'StagePre',
'StageFinal',
'PercChangeRegimens',
'RespRegimens',
'PercChangeTaxane',
'ResponseTaxane',
'PercChangeNonTaxane',
'ResponseNonTaxane')
## QC STEP ##
##### Change ER NA to 0
d$ER[which(d$ER %in% NA)] <- 0
############ Load clincal data#####################
d$ID <- paste('x',d$ID,sep='')
## Just Black and White
d$Race[d$Race %in% c("Other","Hispanic Origin")] = NA
table(d$Race)
# Black White
# 27    80
table(d$Menopause)
table(d$Smoke)
setwd("C:/Users/vestige/Google Drive/AlisonConsult/clinvitro/manova/")
setwd("C:/Users/jrash/ubuntu_share/Google Drive/AlisonConsult/clinvitro/manova/")
setwd("C:/Users/jrash/ubuntu_share/Google Drive/AlisonConsult/clinvitro/analyses/manova/")
## With_genos.tsv
d <- read.table(file = paste(processed.dir,'With_genos.tsv',sep=''),sep='\t',header=TRUE,stringsAsFactors=FALSE,comment.char = "$")
## Remove unnecessary cols
d <- d[,-c(1,3,5,17,18)]
d <- d[,-c(3:13)]
cols <- colnames(d)
colnames(d) <- c('ID','Race',
#"CYP1B1.3","X2B6.6.516","X2B6.6.785","X2C8.3.139","X2C8.3.399","X3A4.1B","X3A5.3C","ABCB1.3435","ABCB1.2677","ABCB1.1236","GSTA1.B",
'Age',
'Menopause',
'Smoke',
'Grade',
'ER',
'ERorPR',
'HER2',
'IHC',
'Regimen',
'Adjuvant',
'NumCycles',
'StartDate',
'EndDate',
'Toxtype',
'ToxGrade',
'ToxCall',
'Neutropenia',
'Myalgia',
'Neuropathy',
'DoseInterval',
'TotalWeeks',
'FollowupStatus',
'StagePre',
'StageFinal',
'PercChangeRegimens',
'RespRegimens',
'PercChangeTaxane',
'ResponseTaxane',
'PercChangeNonTaxane',
'ResponseNonTaxane')
## QC STEP ##
##### Change ER NA to 0
d$ER[which(d$ER %in% NA)] <- 0
############ Load clincal data#####################
d$ID <- paste('x',d$ID,sep='')
## Just Black and White
d$Race[d$Race %in% c("Other","Hispanic Origin")] = NA
table(d$Race)
# Black White
# 27    80
table(d$Menopause)
table(d$Smoke)
processed.dir <- 'C:/Users/jrash/ubuntu_share/Google Drive/AlisonConsult/clinvitro/processed/clinical/'
d <- read.table(file = paste(processed.dir,'With_genos.tsv',sep=''),sep='\t',header=TRUE,stringsAsFactors=FALSE,comment.char = "$")
## Remove unnecessary cols
d <- d[,-c(1,3,5,17,18)]
d <- d[,-c(3:13)]
cols <- colnames(d)
colnames(d) <- c('ID','Race',
#"CYP1B1.3","X2B6.6.516","X2B6.6.785","X2C8.3.139","X2C8.3.399","X3A4.1B","X3A5.3C","ABCB1.3435","ABCB1.2677","ABCB1.1236","GSTA1.B",
'Age',
'Menopause',
'Smoke',
'Grade',
'ER',
'ERorPR',
'HER2',
'IHC',
'Regimen',
'Adjuvant',
'NumCycles',
'StartDate',
'EndDate',
'Toxtype',
'ToxGrade',
'ToxCall',
'Neutropenia',
'Myalgia',
'Neuropathy',
'DoseInterval',
'TotalWeeks',
'FollowupStatus',
'StagePre',
'StageFinal',
'PercChangeRegimens',
'RespRegimens',
'PercChangeTaxane',
'ResponseTaxane',
'PercChangeNonTaxane',
'ResponseNonTaxane')
## QC STEP ##
##### Change ER NA to 0
d$ER[which(d$ER %in% NA)] <- 0
############ Load clincal data#####################
d$ID <- paste('x',d$ID,sep='')
## Just Black and White
d$Race[d$Race %in% c("Other","Hispanic Origin")] = NA
table(d$Race)
# Black White
# 27    80
table(d$Menopause)
table(d$Smoke)
list.of.packages <- c("doParallel","doMC","caret","randomForest")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only = TRUE)
rm(list=ls())
# run on 6 cores
cl <- makeCluster(6)
registerDoParallel(cl)
load("C:/Users/Vestige/Dropbox/FourchesLab/3I60/bigMD/ml_supershort/ML_example.RDATA")
# save your data to all variable
all <- all
# # make pki binary variable
#
# all$pki <- as.factor(ifelse(all$pki > 7, "High", "Low"))
# split in to training and test set
CSARidx <- 1:39
modelidx <- 40:87
data <- all[modelidx, ]
# # if data is binary
#
# fitControl <- trainControl(method = "LOOCV", classProbs = TRUE,
#   summaryFunction = twoClassSummary)
# if data is continuous
fitControl <- trainControl(method = "LOOCV")
?train
fitControl <- trainControl(method = "LOOCV")
set.seed(825)
# a default grid of parameter values is constructed for each tunable parameter
# usually the default works well.  You set the number of values to try for each
# paraemeter with tune length
rfFit <- train(pki~ ., data = data, method = "rf",
trControl = fitControl, verbose = FALSE, tuneLength = 10, metric = "Rsquared")
cl <- makeCluster(6)
registerDoParallel(cl)
load("C:/Users/Vestige/Dropbox/FourchesLab/3I60/bigMD/ml_supershort/ML_example.RDATA")
# save your data to all variable
all <- all
# split in to training and test set
CSARidx <- 1:39
modelidx <- 40:87
data <- all[modelidx, ]
fitControl <- trainControl(method = "LOOCV")
set.seed(825)
# a default grid of parameter values is constructed for each tunable parameter
# usually the default works well.  You set the number of values to try for each
# paraemeter with tune length
rfFit <- train(pki~ ., data = data, method = "rf",
trControl = fitControl, verbose = FALSE, tuneLength = 10, metric = "Rsquared")
head(data)
data <- all[modelidx, ]
d <- all[modelidx, ]
fitControl <- trainControl(method = "LOOCV")
set.seed(825)
load("C:/Users/Vestige/Dropbox/FourchesLab/3I60/bigMD/ml_supershort/ML_example.RDATA")
load("C:/Users/jrash/ubuntu_share/Google Drive/FourchesLab/3I60/bigMD/ml_supershort/ML_example.RDATA")
load("C:/Users/jrash/ubuntu_share/Google Drive/FourchesLab/3I60/bigMD/ml_supershort/ML_example.RDATA")
load("C:/Users/jrash/ubuntu_share/Google Drive/FourchesLab/3I60/big_MD/ml_supershort/ML_example.RDATA")
all <- all
CSARidx <- 1:39
modelidx <- 40:87
d <- all[modelidx, ]
fitControl <- trainControl(method = "LOOCV")
set.seed(825)
# a default grid of parameter values is constructed for each tunable parameter
# usually the default works well.  You set the number of values to try for each
# paraemeter with tune length
head(data)
rfFit <- train(pki~ ., data = d, method = "rf",
trControl = fitControl, verbose = FALSE, tuneLength = 10, metric = "Rsquared")
# see best results
rfFit
# Check performance on CSAR set
preds <- predict.train(rfFit, all[CSARidx, ])
probs <- predict.train(rfFit, all[CSARidx, ], type = "prob")
CSARresults <- twoClassSummary(data.frame(pred = preds, obs = all$pki[CSARidx], probs),
lev = c("High", "Low"))
# Performance on test set
CSARresults
rfFit
?twoClassSummary
?defaultSummary
CSARresults <- postResample(pred = preds, obs = all$pki[CSARidx])
CSARresults
list.of.packages <- c("doParallel","doMC","caret","randomForest")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only = TRUE)
rm(list=ls())
# run on 6 cores
cl <- makeCluster(6)
registerDoParallel(cl)
load("C:/Users/jrash/ubuntu_share/Google Drive/FourchesLab/3I60/big_MD/ml_supershort/ML_example.RDATA")
# save your data to all variable
all <- all
# split in to training and test set
CSARidx <- 1:39
modelidx <- 40:87
d <- all[modelidx, ]
fitControl <- trainControl(method = "LOOCV")
set.seed(825)
# a default grid of parameter values is constructed for each tunable parameter
# usually the default works well.  You set the number of values to try for each
# paraemeter with tune length
head(data)
rfFit <- train(pki~ ., data = d, method = "rf",
trControl = fitControl, verbose = FALSE, tuneLength = 10, metric = "Rsquared")
# see best results
rfFit
# Check performance on CSAR set
preds <- predict.train(rfFit, all[CSARidx, ])
CSARresults <- postResample(pred = preds, obs = all$pki[CSARidx])
# Performance on test set
CSARresults
